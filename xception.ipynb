{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fscore(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory('image_data/train',\n",
    "                                              target_size=(299,299),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2326 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory('image_data/test',\n",
    "                                             target_size=(299,299),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=(10,10,2048)))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    l.called_with = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(299,299,3))\n",
    "x = model(inputs)\n",
    "preds = top_model(x)\n",
    "combined_model = Model(input=inputs, output=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in combined_model.layers[1].layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_model.compile(loss='mse',\n",
    "                       optimizer='sgd',\n",
    "                       metrics=['accuracy', precision, recall, fscore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "1048s - loss: 0.2461 - acc: 0.6372 - precision: 0.6406 - recall: 0.6029 - fscore: 0.5939 - val_loss: 0.2009 - val_acc: 0.6895 - val_precision: 0.6270 - val_recall: 0.9362 - val_fscore: 0.7464\n",
      "Epoch 2/16\n",
      "1040s - loss: 0.2143 - acc: 0.6958 - precision: 0.7068 - recall: 0.7367 - fscore: 0.7061 - val_loss: 0.1619 - val_acc: 0.7871 - val_precision: 0.8014 - val_recall: 0.7489 - val_fscore: 0.7633\n",
      "Epoch 3/16\n",
      "1035s - loss: 0.2074 - acc: 0.6968 - precision: 0.6962 - recall: 0.7142 - fscore: 0.6924 - val_loss: 0.1521 - val_acc: 0.7930 - val_precision: 0.7590 - val_recall: 0.8784 - val_fscore: 0.8106\n",
      "Epoch 4/16\n",
      "1039s - loss: 0.2034 - acc: 0.7129 - precision: 0.7144 - recall: 0.7521 - fscore: 0.7173 - val_loss: 0.1602 - val_acc: 0.7812 - val_precision: 0.7512 - val_recall: 0.8537 - val_fscore: 0.7921\n",
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cathyw/miniconda3/lib/python3.5/site-packages/keras/engine/training.py:1480: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047s - loss: 0.1844 - acc: 0.7424 - precision: 0.7346 - recall: 0.7946 - fscore: 0.7507 - val_loss: 0.1591 - val_acc: 0.7656 - val_precision: 0.7924 - val_recall: 0.7551 - val_fscore: 0.7692\n",
      "Epoch 6/16\n",
      "1044s - loss: 0.1714 - acc: 0.7471 - precision: 0.7381 - recall: 0.7665 - fscore: 0.7420 - val_loss: 0.1470 - val_acc: 0.7940 - val_precision: 0.8006 - val_recall: 0.7927 - val_fscore: 0.7923\n",
      "Epoch 7/16\n",
      "1035s - loss: 0.1710 - acc: 0.7622 - precision: 0.7612 - recall: 0.7917 - fscore: 0.7665 - val_loss: 0.1683 - val_acc: 0.7578 - val_precision: 0.7892 - val_recall: 0.7296 - val_fscore: 0.7499\n",
      "Epoch 8/16\n",
      "1035s - loss: 0.1780 - acc: 0.7466 - precision: 0.7302 - recall: 0.7661 - fscore: 0.7385 - val_loss: 0.1393 - val_acc: 0.8125 - val_precision: 0.7998 - val_recall: 0.8393 - val_fscore: 0.8168\n",
      "Epoch 9/16\n",
      "1042s - loss: 0.1646 - acc: 0.7686 - precision: 0.7663 - recall: 0.7957 - fscore: 0.7711 - val_loss: 0.1543 - val_acc: 0.7865 - val_precision: 0.7513 - val_recall: 0.8526 - val_fscore: 0.7910\n",
      "Epoch 10/16\n",
      "1044s - loss: 0.1577 - acc: 0.7690 - precision: 0.7664 - recall: 0.7856 - fscore: 0.7630 - val_loss: 0.1484 - val_acc: 0.7871 - val_precision: 0.7630 - val_recall: 0.8311 - val_fscore: 0.7936\n",
      "Epoch 11/16\n",
      "1033s - loss: 0.1534 - acc: 0.7749 - precision: 0.7668 - recall: 0.8127 - fscore: 0.7797 - val_loss: 0.1551 - val_acc: 0.7734 - val_precision: 0.7895 - val_recall: 0.6955 - val_fscore: 0.7330\n",
      "Epoch 12/16\n",
      "1040s - loss: 0.1587 - acc: 0.7700 - precision: 0.7651 - recall: 0.7837 - fscore: 0.7650 - val_loss: 0.1472 - val_acc: 0.7884 - val_precision: 0.7706 - val_recall: 0.8360 - val_fscore: 0.7973\n",
      "Epoch 13/16\n",
      "1033s - loss: 0.1527 - acc: 0.7881 - precision: 0.7866 - recall: 0.8242 - fscore: 0.7964 - val_loss: 0.1592 - val_acc: 0.7734 - val_precision: 0.7076 - val_recall: 0.8759 - val_fscore: 0.7760\n",
      "Epoch 14/16\n",
      "1042s - loss: 0.1509 - acc: 0.7878 - precision: 0.7797 - recall: 0.8044 - fscore: 0.7852 - val_loss: 0.1288 - val_acc: 0.8242 - val_precision: 0.8364 - val_recall: 0.8244 - val_fscore: 0.8273\n",
      "Epoch 15/16\n",
      "1035s - loss: 0.1386 - acc: 0.8110 - precision: 0.8122 - recall: 0.8342 - fscore: 0.8130 - val_loss: 0.1374 - val_acc: 0.8242 - val_precision: 0.7966 - val_recall: 0.8309 - val_fscore: 0.8093\n",
      "Epoch 16/16\n",
      "1035s - loss: 0.1377 - acc: 0.8013 - precision: 0.7985 - recall: 0.8209 - fscore: 0.8039 - val_loss: 0.1229 - val_acc: 0.8379 - val_precision: 0.8303 - val_recall: 0.8583 - val_fscore: 0.8395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd048f99f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit_generator(train_generator,\n",
    "                             samples_per_epoch=2048,\n",
    "                             nb_epoch=16,\n",
    "                             validation_data=test_generator,\n",
    "                             nb_val_samples=512,\n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
